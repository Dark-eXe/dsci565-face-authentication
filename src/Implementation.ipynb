{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d364ba50-b6c6-4634-95e5-b5d74e3577a9",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0b0c46-bc83-4d24-8750-9c30bc64c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946b10a8-ba91-4ab6-9ed5-73082b3560cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "path = os.getcwd()\n",
    "path = path[:-4]\n",
    "data_dir = path + \"/data/lfw-deepfunneled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb55beb-5057-4860-8a3c-4f1754a94846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 256 classes\n"
     ]
    }
   ],
   "source": [
    "# get list of LFW names to use: intersection of names in 'people.csv' with names in 'os.listdir(data_dir)'\n",
    "# specify min # of images each LFW subject should have to be considered in experiment: N\n",
    "# N yields k classes (LFW subjects)\n",
    "people = pd.read_csv(path + \"/data/people.csv\")\n",
    "names = [item for item in people[\"name\"].tolist() if item in os.listdir(data_dir)] # intersection of names\n",
    "people = people[people[\"name\"].isin(names)] # filter people DataFrame to intersection\n",
    "\n",
    "N = 6\n",
    "people = people[people.images > N]\n",
    "\n",
    "k = len(people)\n",
    "print(f\"k = {k} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31597b2a-c646-4801-b95a-c375aa6c6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture: pre-trained InceptionV3 transfer learning to k subjects of LFW dataset\n",
    "inceptionv3_transfer = InceptionV3(include_top=False, classes=k, pooling='avg', weights='imagenet')\n",
    "model = keras.Sequential(layers=(inceptionv3_transfer, keras.layers.Dense(k, activation='softmax')))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a109bd-6cf1-40c4-a7b2-61c29e3e0046",
   "metadata": {},
   "source": [
    "## Data Preprocessing $\\rightarrow$ $X_{tr}, y_{tr}, X_{val}, y_{val}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b7d3b76-fafd-4a1e-b4b0-3cad0c2a709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restructure DataFrame\n",
    "people = people.rename(columns={'images': 'num_images'})\n",
    "people = people.set_index('name')\n",
    "\n",
    "# process 250x250 image data as 299x299 image elements under respective person\n",
    "image_col = []\n",
    "for person in people.iterrows():\n",
    "    person = person[1]\n",
    "    image_list = []\n",
    "    for i in range(int(person[\"num_images\"])):\n",
    "        image_path = data_dir + '/' + person.name + '/' + person.name + '_' +  \"{:04d}\".format(i+1) + '.jpg'\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (299, 299))\n",
    "        image_list.append(image)\n",
    "    image_col.append(image_list)\n",
    "people[\"images\"] = image_col\n",
    "\n",
    "# num_images == len(images) for each person\n",
    "assert ([len(x) for x in people[\"images\"]] == people[\"num_images\"].values).all()\n",
    "\n",
    "# construct dataset DataFrame (precursor to X, y) with each row sample as the individual images\n",
    "dataset = [] # element: (image, person, train or test)\n",
    "for person in people.iterrows():\n",
    "    person = person[1]\n",
    "    image_list = person[\"images\"]\n",
    "    num_images = len(image_list)\n",
    "    num_test_images = int(np.floor(num_images * 0.2))\n",
    "    test_i = np.random.choice(num_images, num_test_images)\n",
    "    for i in range(num_images):\n",
    "        image = image_list[i]\n",
    "        element = [image, person.name, \"test\" if i in test_i else \"train\"]\n",
    "        dataset.append(element)\n",
    "dataset = pd.DataFrame(dataset, columns=[\"image\", \"person\", \"split\"])\n",
    "\n",
    "# one-hot encode 'person' (will be used as y)\n",
    "dataset = pd.get_dummies(dataset, columns=['person'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664ff83d-cb27-411e-a46d-f49e021d345a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>split</th>\n",
       "      <th>person_Abdullah_Gul</th>\n",
       "      <th>person_Adrien_Brody</th>\n",
       "      <th>person_Al_Gore</th>\n",
       "      <th>person_Al_Sharpton</th>\n",
       "      <th>person_Alejandro_Toledo</th>\n",
       "      <th>person_Ali_Naimi</th>\n",
       "      <th>person_Alvaro_Uribe</th>\n",
       "      <th>person_Amelia_Vega</th>\n",
       "      <th>...</th>\n",
       "      <th>person_Walter_Mondale</th>\n",
       "      <th>person_Wen_Jiabao</th>\n",
       "      <th>person_William_Donaldson</th>\n",
       "      <th>person_William_Ford_Jr</th>\n",
       "      <th>person_Winona_Ryder</th>\n",
       "      <th>person_Yao_Ming</th>\n",
       "      <th>person_Yashwant_Sinha</th>\n",
       "      <th>person_Yasser_Arafat</th>\n",
       "      <th>person_Yoriko_Kawaguchi</th>\n",
       "      <th>person_Zhu_Rongji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0, 1, 1], [0, 1, 1], [0, 1, 1], [0, 1, 1], ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [1, 0, 0], [2, 0, 0], ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[129, 163, 176], [129, 163, 176], [129, 163,...</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  split  \\\n",
       "0  [[[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], ...  train   \n",
       "1  [[[0, 1, 1], [0, 1, 1], [0, 1, 1], [0, 1, 1], ...  train   \n",
       "2  [[[0, 0, 0], [0, 0, 0], [1, 0, 0], [2, 0, 0], ...  train   \n",
       "3  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  train   \n",
       "4  [[[129, 163, 176], [129, 163, 176], [129, 163,...   test   \n",
       "\n",
       "   person_Abdullah_Gul  person_Adrien_Brody  person_Al_Gore  \\\n",
       "0                False                False           False   \n",
       "1                False                False           False   \n",
       "2                False                False           False   \n",
       "3                False                False           False   \n",
       "4                False                False           False   \n",
       "\n",
       "   person_Al_Sharpton  person_Alejandro_Toledo  person_Ali_Naimi  \\\n",
       "0               False                    False             False   \n",
       "1               False                    False             False   \n",
       "2               False                    False             False   \n",
       "3               False                    False             False   \n",
       "4               False                    False             False   \n",
       "\n",
       "   person_Alvaro_Uribe  person_Amelia_Vega  ...  person_Walter_Mondale  \\\n",
       "0                False               False  ...                  False   \n",
       "1                False               False  ...                  False   \n",
       "2                False               False  ...                  False   \n",
       "3                False               False  ...                  False   \n",
       "4                False               False  ...                  False   \n",
       "\n",
       "   person_Wen_Jiabao  person_William_Donaldson  person_William_Ford_Jr  \\\n",
       "0              False                     False                   False   \n",
       "1              False                     False                   False   \n",
       "2              False                     False                   False   \n",
       "3              False                     False                   False   \n",
       "4              False                     False                   False   \n",
       "\n",
       "   person_Winona_Ryder  person_Yao_Ming  person_Yashwant_Sinha  \\\n",
       "0                False            False                  False   \n",
       "1                False            False                  False   \n",
       "2                False            False                  False   \n",
       "3                False            False                  False   \n",
       "4                False            False                  False   \n",
       "\n",
       "   person_Yasser_Arafat  person_Yoriko_Kawaguchi  person_Zhu_Rongji  \n",
       "0                 False                    False              False  \n",
       "1                 False                    False              False  \n",
       "2                 False                    False              False  \n",
       "3                 False                    False              False  \n",
       "4                 False                    False              False  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9205397b-a6f9-437a-9b30-f55b68402984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify X, y\n",
    "X_train = dataset[dataset[\"split\"] == \"train\"][\"image\"].tolist()\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "X_test = dataset[dataset[\"split\"] == \"test\"][\"image\"].tolist()\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "\n",
    "y_train = dataset[dataset[\"split\"] == \"train\"].drop(['image', 'split'], axis=1)\n",
    "y_test = dataset[dataset[\"split\"] == \"test\"].drop(['image', 'split'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da6d84-bda8-49c0-8c6c-43715866b8a3",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb81b1b4-c3c4-4159-976b-ecd8547dcece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1069s\u001b[0m 8s/step - accuracy: 0.1661 - loss: 4.7156\n",
      "Epoch 2/10\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1075s\u001b[0m 8s/step - accuracy: 0.5840 - loss: 2.1550\n",
      "Epoch 3/10\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1076s\u001b[0m 8s/step - accuracy: 0.8695 - loss: 0.8649\n",
      "Epoch 4/10\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1093s\u001b[0m 8s/step - accuracy: 0.9826 - loss: 0.2887\n",
      "Epoch 5/10\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1072s\u001b[0m 8s/step - accuracy: 0.9986 - loss: 0.0872\n",
      "Epoch 6/10\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1101s\u001b[0m 8s/step - accuracy: 1.0000 - loss: 0.0351\n",
      "Epoch 7/10\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1087s\u001b[0m 8s/step - accuracy: 1.0000 - loss: 0.0218\n",
      "Epoch 8/10\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1079s\u001b[0m 8s/step - accuracy: 1.0000 - loss: 0.0139\n",
      "Epoch 9/10\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4814s\u001b[0m 36s/step - accuracy: 1.0000 - loss: 0.0105\n",
      "Epoch 10/10\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7228s\u001b[0m 55s/step - accuracy: 1.0000 - loss: 0.0081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31024abd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, shuffle=True, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7bb06-20be-4ab2-b36a-d35bb7d6c0eb",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f33e4a6-ebbe-4f96-9981-bb0634888d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 16s/step - accuracy: 0.8692 - loss: 0.5198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4817023277282715, 0.8824228048324585]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a405455-4a6e-4b7d-92ca-34c7effbb90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
