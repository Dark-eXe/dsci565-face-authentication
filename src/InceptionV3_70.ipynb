{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d364ba50-b6c6-4634-95e5-b5d74e3577a9",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "InceptionV3 with $N=70$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0b0c46-bc83-4d24-8750-9c30bc64c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946b10a8-ba91-4ab6-9ed5-73082b3560cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "path = os.getcwd()\n",
    "path = path[:-4]\n",
    "data_dir = path + \"/data/lfw-deepfunneled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb55beb-5057-4860-8a3c-4f1754a94846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 7 classes\n"
     ]
    }
   ],
   "source": [
    "# get list of LFW names to use: intersection of names in 'people.csv' with names in 'os.listdir(data_dir)'\n",
    "# specify min # of images each LFW subject should have to be considered in experiment: N\n",
    "# N yields k classes (LFW subjects)\n",
    "people = pd.read_csv(path + \"/data/people.csv\")\n",
    "names = [item for item in people[\"name\"].tolist() if item in os.listdir(data_dir)] # intersection of names\n",
    "people = people[people[\"name\"].isin(names)] # filter people DataFrame to intersection\n",
    "\n",
    "N = 70\n",
    "people = people[people.images > N]\n",
    "\n",
    "k = len(people)\n",
    "print(f\"k = {k} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31597b2a-c646-4801-b95a-c375aa6c6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture: pre-trained InceptionV3 transfer learning to k subjects of LFW dataset\n",
    "inceptionv3_transfer = InceptionV3(include_top=False, classes=k, pooling='avg', weights='imagenet')\n",
    "model = keras.Sequential(layers=(inceptionv3_transfer, keras.layers.Dense(k, activation='softmax')))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a109bd-6cf1-40c4-a7b2-61c29e3e0046",
   "metadata": {},
   "source": [
    "## Data Preprocessing $\\rightarrow$ $X_{tr}, y_{tr}, X_{val}, y_{val}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b7d3b76-fafd-4a1e-b4b0-3cad0c2a709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restructure DataFrame\n",
    "people = people.rename(columns={'images': 'num_images'})\n",
    "people = people.set_index('name')\n",
    "\n",
    "# process 250x250 image data as 299x299 image elements under respective person\n",
    "image_col = []\n",
    "for person in people.iterrows():\n",
    "    person = person[1]\n",
    "    image_list = []\n",
    "    for i in range(int(person[\"num_images\"])):\n",
    "        image_path = data_dir + '/' + person.name + '/' + person.name + '_' +  \"{:04d}\".format(i+1) + '.jpg'\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (299, 299))\n",
    "        image_list.append(image)\n",
    "    image_col.append(image_list)\n",
    "people[\"images\"] = image_col\n",
    "\n",
    "# num_images == len(images) for each person\n",
    "assert ([len(x) for x in people[\"images\"]] == people[\"num_images\"].values).all()\n",
    "\n",
    "# construct dataset DataFrame (precursor to X, y) with each row sample as the individual images\n",
    "dataset = [] # element: (image, person, train or test)\n",
    "for person in people.iterrows():\n",
    "    person = person[1]\n",
    "    image_list = person[\"images\"]\n",
    "    num_images = len(image_list)\n",
    "    num_test_images = int(np.floor(num_images * 0.2))\n",
    "    test_i = np.random.choice(num_images, num_test_images)\n",
    "    for i in range(num_images):\n",
    "        image = image_list[i]\n",
    "        element = [image, person.name, \"test\" if i in test_i else \"train\"]\n",
    "        dataset.append(element)\n",
    "dataset = pd.DataFrame(dataset, columns=[\"image\", \"person\", \"split\"])\n",
    "\n",
    "# one-hot encode 'person' (will be used as y)\n",
    "dataset = pd.get_dummies(dataset, columns=['person'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664ff83d-cb27-411e-a46d-f49e021d345a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>split</th>\n",
       "      <th>person_Ariel_Sharon</th>\n",
       "      <th>person_Colin_Powell</th>\n",
       "      <th>person_Donald_Rumsfeld</th>\n",
       "      <th>person_George_W_Bush</th>\n",
       "      <th>person_Gerhard_Schroeder</th>\n",
       "      <th>person_Hugo_Chavez</th>\n",
       "      <th>person_Tony_Blair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0, 4, 0], [0, 4, 0], [0, 4, 0], [0, 4, 0], ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0, 1, 0], [10, 12, 10], [5, 7, 6], [4, 5, 4...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0, 0, 4], [0, 0, 3], [0, 0, 2], [0, 0, 1], ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  split  \\\n",
       "0  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  train   \n",
       "1  [[[0, 4, 0], [0, 4, 0], [0, 4, 0], [0, 4, 0], ...  train   \n",
       "2  [[[0, 1, 0], [10, 12, 10], [5, 7, 6], [4, 5, 4...  train   \n",
       "3  [[[0, 0, 4], [0, 0, 3], [0, 0, 2], [0, 0, 1], ...  train   \n",
       "4  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  train   \n",
       "\n",
       "   person_Ariel_Sharon  person_Colin_Powell  person_Donald_Rumsfeld  \\\n",
       "0                False                False                   False   \n",
       "1                False                False                   False   \n",
       "2                False                False                   False   \n",
       "3                False                False                   False   \n",
       "4                False                False                   False   \n",
       "\n",
       "   person_George_W_Bush  person_Gerhard_Schroeder  person_Hugo_Chavez  \\\n",
       "0                 False                     False                True   \n",
       "1                 False                     False                True   \n",
       "2                 False                     False                True   \n",
       "3                 False                     False                True   \n",
       "4                 False                     False                True   \n",
       "\n",
       "   person_Tony_Blair  \n",
       "0              False  \n",
       "1              False  \n",
       "2              False  \n",
       "3              False  \n",
       "4              False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9205397b-a6f9-437a-9b30-f55b68402984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify X, y\n",
    "X_train = dataset[dataset[\"split\"] == \"train\"][\"image\"].tolist()\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "X_test = dataset[dataset[\"split\"] == \"test\"][\"image\"].tolist()\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "\n",
    "y_train = dataset[dataset[\"split\"] == \"train\"].drop(['image', 'split'], axis=1)\n",
    "y_test = dataset[dataset[\"split\"] == \"test\"].drop(['image', 'split'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da6d84-bda8-49c0-8c6c-43715866b8a3",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb81b1b4-c3c4-4159-976b-ecd8547dcece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 6s/step - accuracy: 0.5724 - loss: 1.2069\n",
      "Epoch 2/10\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 6s/step - accuracy: 0.9952 - loss: 0.0407\n",
      "Epoch 3/10\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 6s/step - accuracy: 0.9981 - loss: 0.0134\n",
      "Epoch 4/10\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 7s/step - accuracy: 0.9914 - loss: 0.0315\n",
      "Epoch 5/10\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 7s/step - accuracy: 0.9901 - loss: 0.0410\n",
      "Epoch 6/10\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 7s/step - accuracy: 0.9995 - loss: 0.0083\n",
      "Epoch 7/10\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 7s/step - accuracy: 0.9937 - loss: 0.0186\n",
      "Epoch 8/10\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 7s/step - accuracy: 0.9985 - loss: 0.0066\n",
      "Epoch 9/10\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 7s/step - accuracy: 0.9984 - loss: 0.0111\n",
      "Epoch 10/10\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 7s/step - accuracy: 0.9999 - loss: 0.0082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x178ed1810>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, shuffle=True, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7bb06-20be-4ab2-b36a-d35bb7d6c0eb",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f33e4a6-ebbe-4f96-9981-bb0634888d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9958 - loss: 0.0282\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abe23419-37d3-410a-84e7-ab0e8e41f0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.036618828773498535\tAccuracy: 0.991304337978363\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss: {loss}\\tAccuracy: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
